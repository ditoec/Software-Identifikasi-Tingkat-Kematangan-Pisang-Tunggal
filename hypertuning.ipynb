{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "## Autotune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras_tuner.tuners import RandomSearch,Hyperband,BayesianOptimization\n",
    "from keras_tuner.engine.hypermodel import HyperModel\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution() // to disable eager\n",
    "print(tf.__version__)\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model & learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/Augmented\"\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "#BUFFER_SIZE = BATCH_SIZE*20\n",
    "#EVALUATION_INTERVAL = round(len(labels)/BATCH_SIZE)\n",
    "#EVALUATION_TIME = round(EVALUATION_INTERVAL / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1365 files belonging to 8 classes.\n",
      "Using 1092 files for training.\n",
      "Found 1365 files belonging to 8 classes.\n",
      "Using 273 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', 'Overripen']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "#AUTOTUNE\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner\\run1\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner\\run1\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 10\n",
      "num_Conv_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "units_Conv_0 (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "rate_DO_Conv_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.1, 'sampling': None}\n",
      "units_Dense (Int)\n",
      "{'default': 16, 'conditions': [], 'min_value': 16, 'max_value': 256, 'step': 16, 'sampling': None}\n",
      "rate_DO_dense (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.2, 'step': 0.05, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.0005, 'conditions': [], 'values': [0.0005, 0.0001, 5e-05, 1e-05], 'ordered': True}\n",
      "units_Conv_1 (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "rate_DO_Conv_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.1, 'sampling': None}\n",
      "units_Conv_2 (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "rate_DO_Conv_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "    for i in range(hp.Int('num_Conv_layers', 3, 4)):\n",
    "    #for i in range(4):\n",
    "        model.add(keras.layers.Conv2D(hp.Int('units_Conv_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=256,\n",
    "                                            default=32,\n",
    "                                            step=32),\n",
    "                               3, padding='same',activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D())\n",
    "        model.add(keras.layers.Dropout(rate=hp.Float('rate_DO_Conv_' + str(i),\n",
    "                                min_value=0.0,\n",
    "                                max_value=0.4,\n",
    "                                default=0.0,\n",
    "                                step=0.1)))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('units_Dense',\n",
    "                                        min_value=16,\n",
    "                                        max_value=256,\n",
    "                                        default=16,\n",
    "                                        step=16),\n",
    "                           activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=hp.Float('rate_DO_dense',\n",
    "                                        min_value=0.0,\n",
    "                                        max_value=0.2,\n",
    "                                        default=0.0,\n",
    "                                        step=0.05)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(num_classes))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[5e-6,1e-6, 5e-5, 1e-5])),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=1000,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner',\n",
    "    project_name='run1')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in tuner\\run1\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000024E43E8C0D0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 192\n",
      "rate_DO_Conv_0: 0.0\n",
      "units_Dense: 160\n",
      "rate_DO_dense: 0.05\n",
      "learning_rate: 5e-05\n",
      "units_Conv_1: 256\n",
      "rate_DO_Conv_1: 0.2\n",
      "units_Conv_2: 32\n",
      "rate_DO_Conv_2: 0.2\n",
      "Score: 0.8974359035491943\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 64\n",
      "rate_DO_Conv_0: 0.0\n",
      "units_Dense: 144\n",
      "rate_DO_dense: 0.15000000000000002\n",
      "learning_rate: 0.0005\n",
      "units_Conv_1: 128\n",
      "rate_DO_Conv_1: 0.30000000000000004\n",
      "units_Conv_2: 128\n",
      "rate_DO_Conv_2: 0.2\n",
      "Score: 0.8937729001045227\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 224\n",
      "rate_DO_Conv_0: 0.1\n",
      "units_Dense: 64\n",
      "rate_DO_dense: 0.15000000000000002\n",
      "learning_rate: 0.0001\n",
      "units_Conv_1: 160\n",
      "rate_DO_Conv_1: 0.30000000000000004\n",
      "units_Conv_2: 96\n",
      "rate_DO_Conv_2: 0.4\n",
      "Score: 0.8901098966598511\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 160\n",
      "rate_DO_Conv_0: 0.0\n",
      "units_Dense: 208\n",
      "rate_DO_dense: 0.05\n",
      "learning_rate: 5e-05\n",
      "units_Conv_1: 160\n",
      "rate_DO_Conv_1: 0.1\n",
      "units_Conv_2: 256\n",
      "rate_DO_Conv_2: 0.1\n",
      "Score: 0.8864468932151794\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 128\n",
      "rate_DO_Conv_0: 0.0\n",
      "units_Dense: 192\n",
      "rate_DO_dense: 0.1\n",
      "learning_rate: 0.0001\n",
      "units_Conv_1: 64\n",
      "rate_DO_Conv_1: 0.30000000000000004\n",
      "units_Conv_2: 64\n",
      "rate_DO_Conv_2: 0.30000000000000004\n",
      "Score: 0.8864468932151794\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 64\n",
      "rate_DO_Conv_0: 0.1\n",
      "units_Dense: 64\n",
      "rate_DO_dense: 0.05\n",
      "learning_rate: 5e-05\n",
      "units_Conv_1: 224\n",
      "rate_DO_Conv_1: 0.30000000000000004\n",
      "units_Conv_2: 32\n",
      "rate_DO_Conv_2: 0.4\n",
      "Score: 0.8827838897705078\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 160\n",
      "rate_DO_Conv_0: 0.0\n",
      "units_Dense: 160\n",
      "rate_DO_dense: 0.1\n",
      "learning_rate: 5e-05\n",
      "units_Conv_1: 224\n",
      "rate_DO_Conv_1: 0.2\n",
      "units_Conv_2: 256\n",
      "rate_DO_Conv_2: 0.0\n",
      "Score: 0.8827838897705078\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 160\n",
      "rate_DO_Conv_0: 0.1\n",
      "units_Dense: 112\n",
      "rate_DO_dense: 0.15000000000000002\n",
      "learning_rate: 0.0005\n",
      "units_Conv_1: 96\n",
      "rate_DO_Conv_1: 0.30000000000000004\n",
      "units_Conv_2: 64\n",
      "rate_DO_Conv_2: 0.30000000000000004\n",
      "Score: 0.8827838897705078\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 192\n",
      "rate_DO_Conv_0: 0.30000000000000004\n",
      "units_Dense: 224\n",
      "rate_DO_dense: 0.1\n",
      "learning_rate: 0.0005\n",
      "units_Conv_1: 192\n",
      "rate_DO_Conv_1: 0.2\n",
      "units_Conv_2: 160\n",
      "rate_DO_Conv_2: 0.1\n",
      "Score: 0.8791208863258362\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_Conv_layers: 3\n",
      "units_Conv_0: 224\n",
      "rate_DO_Conv_0: 0.1\n",
      "units_Dense: 32\n",
      "rate_DO_dense: 0.05\n",
      "learning_rate: 0.0001\n",
      "units_Conv_1: 192\n",
      "rate_DO_Conv_1: 0.2\n",
      "units_Conv_2: 256\n",
      "rate_DO_Conv_2: 0.1\n",
      "Score: 0.8791208863258362\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, epochs=epochs,\n",
    "      validation_data=val_ds)\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
